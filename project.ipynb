{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration A - All tasks come from same dataset for training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install medmnist\n",
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F  # pylint: disable=unused-import\n",
    "from torch.utils import tensorboard\n",
    "\n",
    "from torch import autograd\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "import os\n",
    "import math\n",
    "\n",
    "import medmnist\n",
    "from medmnist import INFO, Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MedMNIST v{medmnist.__version__} @ {medmnist.HOMEPAGE}\")\n",
    "import sys\n",
    "print(\"Python version:\", sys.version)\n",
    "platform = sys.platform\n",
    "\n",
    "if platform == \"linux\":\n",
    "    sys.stdout = open('/dev/stdout', 'w')\n",
    "    import torch.multiprocessing\n",
    "else:\n",
    "    !pip install multiprocess\n",
    "    import multiprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We first work on a 2D dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, we read the MedMNIST data, preprocess them and encapsulate them into dataloader form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_flags = ['pathmnist', 'dermamnist']\n",
    "\n",
    "# preprocessingt\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "download = True\n",
    "\n",
    "for data_flag in data_flags:\n",
    "    \n",
    "    info = INFO[data_flag]\n",
    "    task = info['task']\n",
    "    n_channels = info['n_channels']\n",
    "    n_classes = len(info['label'])\n",
    "    \n",
    "    DataClass = getattr(medmnist, info['python_class'])\n",
    "    print(data_flag)\n",
    "    print(task)\n",
    "    \n",
    "    train_dataset = DataClass(split='train', transform=data_transform, download=download)\n",
    "    val_dataset = DataClass(split='val', transform=data_transform, download=False)\n",
    "    test_dataset = DataClass(split='test', transform=data_transform, download=download)\n",
    "\n",
    "    print(train_dataset)\n",
    "    train_dataset.montage(length=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import dataset, sampler, dataloader\n",
    "from pathlib import Path\n",
    "\n",
    "NUM_SAMPLES_PER_CLASS = 30\n",
    "\n",
    "class MedMNISTDataset(dataset.Dataset):\n",
    "\n",
    "    def __init__(self, medmnistdataset, split, num_way, num_support, num_query):\n",
    "        super().__init__()\n",
    "\n",
    "        info = INFO[medmnistdataset]\n",
    "        task = info['task']\n",
    "        n_channels = info['n_channels']\n",
    "        n_classes = len(info['label'])\n",
    "        DataClass = getattr(medmnist, info['python_class'])\n",
    "\n",
    "        split_labels = None\n",
    "        if (split == 'train'):\n",
    "            split_labels = 'train_labels'\n",
    "            dataset = DataClass(split='train', transform=data_transform, download=download)\n",
    "        elif (split == 'val'):\n",
    "            split_labels = 'val_labels'\n",
    "            dataset = DataClass(split='val', transform=data_transform, download=download)\n",
    "        elif (split == 'test'):\n",
    "            split_labels = 'test_labels'\n",
    "            dataset = DataClass(split='test', transform=data_transform, download=download)\n",
    "\n",
    "        if platform == \"linux\":\n",
    "            self.data = np.load(Path(\"/home/azureuser/.medmnist/\" + medmnistdataset + \".npz\"))\n",
    "        else:\n",
    "            self.data = np.load(Path(\"/Users/angel/.medmnist/\" + medmnistdataset + \".npz\"))\n",
    "            \n",
    "        all_labels = []\n",
    "        for elem in self.data[split_labels]:\n",
    "            all_labels.append(elem)\n",
    "\n",
    "        num_classes = len(np.unique(all_labels))\n",
    "\n",
    "        self.all_images = []\n",
    "        for image,_ in dataset:\n",
    "            self.all_images.append(image)\n",
    "            \n",
    "        self.images_indices = [None] * num_classes\n",
    "        for i in range(num_classes):\n",
    "            self.images_indices[i] = []\n",
    "            \n",
    "        for i, elem in enumerate(all_labels):\n",
    "            if elem.item() >= num_classes: continue\n",
    "            self.images_indices[elem.item()].append(i)\n",
    "        \n",
    "        # shuffle characters\n",
    "        for i in range(num_classes):\n",
    "            np.random.default_rng(0).shuffle(self.images_indices[i])\n",
    "\n",
    "        # check problem arguments\n",
    "        assert num_support + num_query <= NUM_SAMPLES_PER_CLASS\n",
    "        self._num_support = num_support\n",
    "        self._num_query = num_query\n",
    "        self.split = split\n",
    "\n",
    "    def __getitem__(self, class_idxs):\n",
    "        \"\"\"Constructs a task.\n",
    "\n",
    "        Data for each class is sampled uniformly at random without replacement.\n",
    "\n",
    "        Args:\n",
    "            class_idxs (tuple[int]): class indices that comprise the task\n",
    "\n",
    "        Returns:\n",
    "            images_support (Tensor): task support images\n",
    "                shape (num_way * num_support, channels, height, width)\n",
    "            labels_support (Tensor): task support labels\n",
    "                shape (num_way * num_support,)\n",
    "            images_query (Tensor): task query images\n",
    "                shape (num_way * num_query, channels, height, width)\n",
    "            labels_query (Tensor): task query labels\n",
    "                shape (num_way * num_query,)\n",
    "        \"\"\"\n",
    "        images_support, images_query = [], []\n",
    "        labels_support, labels_query = [], []\n",
    "\n",
    "        for label in class_idxs:\n",
    "            replace = False\n",
    "            if self.split == 'val' or self.split == 'test':\n",
    "                replace = True\n",
    "            # get a class's examples and sample from them\n",
    "            images_indices_label = np.random.default_rng().choice(\n",
    "                self.images_indices[label],\n",
    "                size=self._num_support + self._num_query,\n",
    "                replace=replace\n",
    "            )\n",
    "\n",
    "            images = []\n",
    "            for index in images_indices_label:\n",
    "                images.append(self.all_images[index])\n",
    "                \n",
    "            # split sampled examples into support and query\n",
    "            images_support.extend(images[:self._num_support])\n",
    "            images_query.extend(images[self._num_support:])\n",
    "            labels_support.extend([label] * self._num_support)\n",
    "            labels_query.extend([label] * self._num_query)\n",
    "\n",
    "        # aggregate into tensors\n",
    "        images_support = torch.stack(images_support)  # shape (N*S, C, H, W)\n",
    "        labels_support = torch.tensor(labels_support)  # shape (N*S)\n",
    "        images_query = torch.stack(images_query)\n",
    "        labels_query = torch.tensor(labels_query)\n",
    "\n",
    "        return images_support, labels_support, images_query, labels_query\n",
    "\n",
    "\n",
    "class MedMNISTSampler(sampler.Sampler):\n",
    "    \"\"\"Samples task specification keys for an MedMNISTDataset.\"\"\"\n",
    "\n",
    "    def __init__(self, split_idxs, num_way, num_tasks):\n",
    "        \"\"\"Inits OmniglotSampler.\n",
    "\n",
    "        Args:\n",
    "            split_idxs (range): indices that comprise the\n",
    "                training/validation/test split\n",
    "            num_way (int): number of classes per task\n",
    "            num_tasks (int): number of tasks to sample\n",
    "        \"\"\"\n",
    "        super().__init__(None)\n",
    "        self._split_idxs = split_idxs\n",
    "        self._num_way = num_way\n",
    "        self._num_tasks = num_tasks\n",
    "\n",
    "    def __iter__(self):\n",
    "        return (\n",
    "            np.random.default_rng().choice(\n",
    "                self._split_idxs,\n",
    "                size=self._num_way,\n",
    "                replace=False\n",
    "            ) for _ in range(self._num_tasks)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._num_tasks\n",
    "\n",
    "\n",
    "def identity(x):\n",
    "    return x\n",
    "\n",
    "\n",
    "def get_medmnist_dataloader(\n",
    "        medmnistdataset,\n",
    "        split,\n",
    "        batch_size,\n",
    "        num_way,\n",
    "        num_support,\n",
    "        num_query,\n",
    "        num_tasks_per_epoch,\n",
    "        num_workers=2,\n",
    "):\n",
    "    \"\"\"Returns a dataloader.DataLoader for Omniglot.\n",
    "\n",
    "    Args:\n",
    "        split (str): one of 'train', 'val', 'test'\n",
    "        batch_size (int): number of tasks per batch\n",
    "        num_way (int): number of classes per task\n",
    "        num_support (int): number of support examples per class\n",
    "        num_query (int): number of query examples per class\n",
    "        num_tasks_per_epoch (int): number of tasks before DataLoader is\n",
    "            exhausted\n",
    "    \"\"\"\n",
    "    split_idxs = range(num_way)\n",
    "\n",
    "    return dataloader.DataLoader(\n",
    "        dataset=MedMNISTDataset(medmnistdataset, split, num_way, num_support, num_query),\n",
    "        batch_size=batch_size,\n",
    "        sampler=MedMNISTSampler(split_idxs, num_way, num_tasks_per_epoch),\n",
    "        num_workers=num_workers,\n",
    "        multiprocessing_context=\"fork\",\n",
    "        collate_fn=identity,\n",
    "        pin_memory=torch.cuda.is_available(),\n",
    "        drop_last=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test custom dataloader\n",
    "# num_workers = 10\n",
    "# if platform == \"linux\":\n",
    "#     num_workers = 10\n",
    "\n",
    "# dataloader_meta_train = get_medmnist_dataloader(\n",
    "#         medmnistdataset='pathmnist',\n",
    "#         split='train',\n",
    "#         batch_size=8,\n",
    "#         num_way=9,\n",
    "#         num_support=1,\n",
    "#         num_query=15,\n",
    "#         num_tasks_per_epoch=240,\n",
    "#         num_workers=num_workers,\n",
    "#     )\n",
    "\n",
    "# tasks = next(iter(dataloader_meta_train))\n",
    "# for task in tasks:\n",
    "#     images_support, labels_support, images_query, labels_query = task\n",
    "#     print(images_support.shape)\n",
    "#     print(labels_support.shape)\n",
    "#     print(images_query.shape)\n",
    "#     print(labels_query.shape)\n",
    "#     break\n",
    "\n",
    "# dataloader_meta_val = get_medmnist_dataloader(\n",
    "#         medmnistdataset='bloodmnist',\n",
    "#         split='val',\n",
    "#         batch_size=8,\n",
    "#         num_way=8,\n",
    "#         num_support=1,\n",
    "#         num_query=15,\n",
    "#         num_tasks_per_epoch=240,\n",
    "#         num_workers=num_workers,\n",
    "#     )\n",
    "\n",
    "# tasks = next(iter(dataloader_meta_val))\n",
    "# for task in tasks:\n",
    "#     images_support, labels_support, images_query, labels_query = task\n",
    "#     print(images_support.shape)\n",
    "#     print(labels_support.shape)\n",
    "#     print(images_query.shape)\n",
    "#     print(labels_query.shape)\n",
    "#     break\n",
    "\n",
    "# dataloader_meta_test = get_medmnist_dataloader(\n",
    "#         medmnistdataset='dermamnist',\n",
    "#         split='test',\n",
    "#         batch_size=8,\n",
    "#         num_way=7,\n",
    "#         num_support=1,\n",
    "#         num_query=15,\n",
    "#         num_tasks_per_epoch=240,\n",
    "#         num_workers=num_workers,\n",
    "#     )\n",
    "\n",
    "# tasks = next(iter(dataloader_meta_test))\n",
    "# for task in tasks:\n",
    "#     images_support, labels_support, images_query, labels_query = task\n",
    "#     print(images_support.shape)\n",
    "#     print(labels_support.shape)\n",
    "#     print(images_query.shape)\n",
    "#     print(labels_query.shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Then, we define a simple model for illustration, object function and optimizer that we use to classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(logits, labels):\n",
    "    \"\"\"Returns the mean accuracy of a model's predictions on a set of examples.\n",
    "\n",
    "    Args:\n",
    "        logits (torch.Tensor): model predicted logits\n",
    "            shape (examples, classes)\n",
    "        labels (torch.Tensor): classification labels from 0 to num_classes - 1\n",
    "            shape (examples,)\n",
    "    \"\"\"\n",
    "\n",
    "    assert logits.dim() == 2\n",
    "    assert labels.dim() == 1\n",
    "    assert logits.shape[0] == labels.shape[0]\n",
    "    y = torch.argmax(logits, dim=-1) == labels\n",
    "    y = y.type(torch.float)\n",
    "    return torch.mean(y).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_INPUT_CHANNELS = 3\n",
    "NUM_HIDDEN_CHANNELS = 32\n",
    "KERNEL_SIZE = 3\n",
    "NUM_CONV_LAYERS = 8\n",
    "SUMMARY_INTERVAL = 10\n",
    "SAVE_INTERVAL = 100\n",
    "LOG_INTERVAL = 10\n",
    "VAL_INTERVAL = LOG_INTERVAL * 5\n",
    "NUM_TEST_TASKS = 100\n",
    "\n",
    "class MAML:\n",
    "    \"\"\"Trains and assesses a MAML.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_outputs,\n",
    "            num_inner_steps,\n",
    "            inner_lr,\n",
    "            learn_inner_lrs,\n",
    "            outer_lr,\n",
    "            log_dir,\n",
    "            device\n",
    "    ):\n",
    "        \"\"\"Inits MAML.\n",
    "\n",
    "        The network consists of four convolutional blocks followed by a linear\n",
    "        head layer. Each convolutional block comprises a convolution layer, a\n",
    "        batch normalization layer, and ReLU activation.\n",
    "\n",
    "        Note that unlike conventional use, batch normalization is always done\n",
    "        with batch statistics, regardless of whether we are training or\n",
    "        evaluating. This technically makes meta-learning transductive, as\n",
    "        opposed to inductive.\n",
    "\n",
    "        Args:\n",
    "            num_outputs (int): dimensionality of output, i.e. number of classes\n",
    "                in a task\n",
    "            num_inner_steps (int): number of inner-loop optimization steps\n",
    "            inner_lr (float): learning rate for inner-loop optimization\n",
    "                If learn_inner_lrs=True, inner_lr serves as the initialization\n",
    "                of the learning rates.\n",
    "            learn_inner_lrs (bool): whether to learn the above\n",
    "            outer_lr (float): learning rate for outer-loop optimization\n",
    "            log_dir (str): path to logging directory\n",
    "            device (str): device to be used\n",
    "        \"\"\"\n",
    "        meta_parameters = {}\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        # construct feature extractor\n",
    "        in_channels = NUM_INPUT_CHANNELS\n",
    "        for i in range(NUM_CONV_LAYERS):\n",
    "            meta_parameters[f'conv{i}'] = nn.init.xavier_uniform_(\n",
    "                torch.empty(\n",
    "                    NUM_HIDDEN_CHANNELS,\n",
    "                    in_channels,\n",
    "                    KERNEL_SIZE,\n",
    "                    KERNEL_SIZE,\n",
    "                    requires_grad=True,\n",
    "                    device=self.device\n",
    "                )\n",
    "            )\n",
    "            meta_parameters[f'b{i}'] = nn.init.zeros_(\n",
    "                torch.empty(\n",
    "                    NUM_HIDDEN_CHANNELS,\n",
    "                    requires_grad=True,\n",
    "                    device=self.device\n",
    "                )\n",
    "            )\n",
    "            in_channels = NUM_HIDDEN_CHANNELS\n",
    "\n",
    "        # construct linear head layer\n",
    "        meta_parameters[f'w{NUM_CONV_LAYERS}'] = nn.init.xavier_uniform_(\n",
    "            torch.empty(\n",
    "                num_outputs,\n",
    "                NUM_HIDDEN_CHANNELS,\n",
    "                requires_grad=True,\n",
    "                device=self.device\n",
    "            )\n",
    "        )\n",
    "        meta_parameters[f'b{NUM_CONV_LAYERS}'] = nn.init.zeros_(\n",
    "            torch.empty(\n",
    "                num_outputs,\n",
    "                requires_grad=True,\n",
    "                device=self.device\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self._meta_parameters = meta_parameters\n",
    "        self._num_inner_steps = num_inner_steps\n",
    "        self._inner_lrs = {\n",
    "            k: torch.tensor(inner_lr, requires_grad=learn_inner_lrs)\n",
    "            for k in self._meta_parameters.keys()\n",
    "        }\n",
    "        self._outer_lr = outer_lr\n",
    "\n",
    "        self._optimizer = torch.optim.Adam(\n",
    "            list(self._meta_parameters.values()) +\n",
    "            list(self._inner_lrs.values()),\n",
    "            lr=self._outer_lr\n",
    "        )\n",
    "        self._log_dir = log_dir\n",
    "        os.makedirs(self._log_dir, exist_ok=True)\n",
    "\n",
    "        self._start_train_step = 0\n",
    "\n",
    "    def _forward(self, images, parameters):\n",
    "        \"\"\"Computes predicted classification logits.\n",
    "\n",
    "        Args:\n",
    "            images (Tensor): batch of Omniglot images\n",
    "                shape (num_images, channels, height, width)\n",
    "            parameters (dict[str, Tensor]): parameters to use for\n",
    "                the computation\n",
    "\n",
    "        Returns:\n",
    "            a Tensor consisting of a batch of logits\n",
    "                shape (num_images, classes)\n",
    "        \"\"\"\n",
    "        x = images\n",
    "        for i in range(NUM_CONV_LAYERS):\n",
    "            x = F.conv2d(\n",
    "                input=x,\n",
    "                weight=parameters[f'conv{i}'],\n",
    "                bias=parameters[f'b{i}'],\n",
    "                stride=1,\n",
    "                padding='same'\n",
    "            )\n",
    "            x = F.batch_norm(x, None, None, training=True)\n",
    "            x = F.leaky_relu(x)\n",
    "        x = torch.mean(x, dim=[2, 3])\n",
    "        return F.linear(\n",
    "            input=x,\n",
    "            weight=parameters[f'w{NUM_CONV_LAYERS}'],\n",
    "            bias=parameters[f'b{NUM_CONV_LAYERS}']\n",
    "        )\n",
    "\n",
    "    def _inner_loop(self, images, labels, train):\n",
    "        \"\"\"Computes the adapted network parameters via the MAML inner loop.\n",
    "\n",
    "        Args:\n",
    "            images (Tensor): task support set inputs\n",
    "                shape (num_images, channels, height, width)\n",
    "            labels (Tensor): task support set outputs\n",
    "                shape (num_images,)\n",
    "            train (bool): whether we are training or evaluating\n",
    "\n",
    "        Returns:\n",
    "            parameters (dict[str, Tensor]): adapted network parameters\n",
    "            accuracies (list[float]): support set accuracy over the course of\n",
    "                the inner loop, length num_inner_steps + 1\n",
    "            gradients(list[float]): gradients computed from auto.grad, just needed\n",
    "                for autograders, no need to use this value in your code and feel to replace\n",
    "                with underscore       \n",
    "        \"\"\"\n",
    "        accuracies = []\n",
    "        parameters = {\n",
    "            k: torch.clone(v)\n",
    "            for k, v in self._meta_parameters.items()\n",
    "        }\n",
    "        gradients = None\n",
    "        ### START CODE HERE ###\n",
    "        # TODO: finish implementing this method.\n",
    "        # This method computes the inner loop (adaptation) procedure\n",
    "        # over the course of _num_inner_steps steps for one\n",
    "        # task. It also scores the model along the way.\n",
    "        # Make sure to populate accuracies and update parameters.\n",
    "        # Use F.cross_entropy to compute classification losses.\n",
    "        # Use util.score to compute accuracies.\n",
    "        for _ in range(self._num_inner_steps):\n",
    "            support_features = self._forward(images, parameters=parameters)\n",
    "            loss = F.cross_entropy(support_features, labels.squeeze())\n",
    "\n",
    "            if train:\n",
    "                gradients = autograd.grad(loss, parameters.values(), create_graph=True)\n",
    "            else:\n",
    "                gradients = autograd.grad(loss, parameters.values(), create_graph=False)\n",
    "\n",
    "            layers = list(parameters.keys())\n",
    "            for i in range(len(layers)): parameters[layers[i]] = parameters[layers[i]] - self._inner_lrs[layers[i]] * gradients[i]\n",
    "            accuracies.append(score(support_features, labels.squeeze()))\n",
    "\n",
    "        # Batch accuracy\n",
    "        batch_features = self._forward(images, parameters)\n",
    "        accuracies.append(score(batch_features, labels.squeeze()))\n",
    "\n",
    "        ### END CODE HERE ###\n",
    "        return parameters, accuracies, gradients\n",
    "\n",
    "    def _outer_step(self, task_batch, train):\n",
    "        \"\"\"Computes the MAML loss and metrics on a batch of tasks.\n",
    "\n",
    "        Args:\n",
    "            task_batch (tuple): batch of tasks from an Omniglot DataLoader\n",
    "            train (bool): whether we are training or evaluating\n",
    "\n",
    "        Returns:\n",
    "            outer_loss (Tensor): mean MAML loss over the batch, scalar\n",
    "            accuracies_support (ndarray): support set accuracy over the\n",
    "                course of the inner loop, averaged over the task batch\n",
    "                shape (num_inner_steps + 1,)\n",
    "            accuracy_query (float): query set accuracy of the adapted\n",
    "                parameters, averaged over the task batch\n",
    "        \"\"\"\n",
    "        outer_loss_batch = []\n",
    "        accuracies_support_batch = []\n",
    "        accuracy_query_batch = []\n",
    "        for i, task in enumerate(task_batch):\n",
    "            images_support, labels_support, images_query, labels_query = task\n",
    "            images_support = images_support.to(self.device)\n",
    "            labels_support = labels_support.to(self.device)\n",
    "            images_query = images_query.to(self.device)\n",
    "            labels_query = labels_query.to(self.device)\n",
    "\n",
    "            parameters, support_accuraccies, _ = self._inner_loop(images_support, labels_support, train)\n",
    "\n",
    "            query_features = self._forward(images_query, parameters)\n",
    "            loss = F.cross_entropy(query_features, labels_query.squeeze())\n",
    "            outer_loss_batch.append(loss)\n",
    "\n",
    "            accuracies_support_batch.append(support_accuraccies)\n",
    "            query_accuracies = score(query_features, labels_query.squeeze())\n",
    "            accuracy_query_batch.append(query_accuracies)\n",
    "            ### END CODE HERE ###\n",
    "        outer_loss = torch.mean(torch.stack(outer_loss_batch))\n",
    "        accuracies_support = np.mean(\n",
    "            accuracies_support_batch,\n",
    "            axis=0\n",
    "        )\n",
    "        accuracy_query = np.mean(accuracy_query_batch)\n",
    "        return outer_loss, accuracies_support, accuracy_query\n",
    "\n",
    "    def train(self, dataloader_meta_train, dataloader_meta_val, writer):\n",
    "        \"\"\"Train the MAML.\n",
    "\n",
    "        Consumes dataloader_meta_train to optimize MAML meta-parameters\n",
    "        while periodically validating on dataloader_meta_val, logging metrics, and\n",
    "        saving checkpoints.\n",
    "\n",
    "        Args:\n",
    "            dataloader_meta_train (DataLoader): loader for train tasks\n",
    "            dataloader_meta_val (DataLoader): loader for validation tasks\n",
    "            writer (SummaryWriter): TensorBoard logger\n",
    "        \"\"\"\n",
    "        print(f'Starting training at iteration {self._start_train_step}.')\n",
    "        for i_step, task_batch in enumerate(\n",
    "                dataloader_meta_train,\n",
    "                start=self._start_train_step\n",
    "        ):\n",
    "            self._optimizer.zero_grad()\n",
    "            outer_loss, accuracies_support, accuracy_query = (                self._outer_step(task_batch, train=True)\n",
    "            )\n",
    "            outer_loss.backward()\n",
    "            self._optimizer.step()\n",
    "\n",
    "            if i_step % LOG_INTERVAL == 0:\n",
    "                print(\n",
    "                    f'Iteration {i_step}: '\n",
    "                    f'loss: {outer_loss.item():.3f}, '\n",
    "                    f'pre-adaptation support accuracy: '\n",
    "                    f'{accuracies_support[0]:.3f}, '\n",
    "                    f'post-adaptation support accuracy: '\n",
    "                    f'{accuracies_support[-1]:.3f}, '\n",
    "                    f'post-adaptation query accuracy: '\n",
    "                    f'{accuracy_query:.3f}'\n",
    "                )\n",
    "                writer.add_scalar('loss/train', outer_loss.item(), i_step)\n",
    "                writer.add_scalar(\n",
    "                    'train_accuracy/pre_adapt_support',\n",
    "                    accuracies_support[0],\n",
    "                    i_step\n",
    "                )\n",
    "                writer.add_scalar(\n",
    "                    'train_accuracy/post_adapt_support',\n",
    "                    accuracies_support[-1],\n",
    "                    i_step\n",
    "                )\n",
    "                writer.add_scalar(\n",
    "                    'train_accuracy/post_adapt_query',\n",
    "                    accuracy_query,\n",
    "                    i_step\n",
    "                )\n",
    "\n",
    "            if i_step % VAL_INTERVAL == 0:\n",
    "                losses = []\n",
    "                accuracies_pre_adapt_support = []\n",
    "                accuracies_post_adapt_support = []\n",
    "                accuracies_post_adapt_query = []\n",
    "                for val_task_batch in dataloader_meta_val:\n",
    "                    outer_loss, accuracies_support, accuracy_query = (\n",
    "                        self._outer_step(val_task_batch, train=False)\n",
    "                    )\n",
    "                    if (math.isnan(outer_loss.item())): break\n",
    "                    losses.append(outer_loss.item())\n",
    "                    accuracies_pre_adapt_support.append(accuracies_support[0])\n",
    "                    accuracies_post_adapt_support.append(accuracies_support[-1])\n",
    "                    accuracies_post_adapt_query.append(accuracy_query)\n",
    "                loss = np.mean(losses)\n",
    "                accuracy_pre_adapt_support = np.mean(\n",
    "                    accuracies_pre_adapt_support\n",
    "                )\n",
    "                accuracy_post_adapt_support = np.mean(\n",
    "                    accuracies_post_adapt_support\n",
    "                )\n",
    "                accuracy_post_adapt_query = np.mean(\n",
    "                    accuracies_post_adapt_query\n",
    "                )\n",
    "                print(\n",
    "                    f'Validation: '\n",
    "                    f'loss: {loss:.3f}, '\n",
    "                    f'pre-adaptation support accuracy: '\n",
    "                    f'{accuracy_pre_adapt_support:.3f}, '\n",
    "                    f'post-adaptation support accuracy: '\n",
    "                    f'{accuracy_post_adapt_support:.3f}, '\n",
    "                    f'post-adaptation query accuracy: '\n",
    "                    f'{accuracy_post_adapt_query:.3f}'\n",
    "                )\n",
    "                writer.add_scalar('loss/val', loss, i_step)\n",
    "                writer.add_scalar(\n",
    "                    'val_accuracy/pre_adapt_support',\n",
    "                    accuracy_pre_adapt_support,\n",
    "                    i_step\n",
    "                )\n",
    "                writer.add_scalar(\n",
    "                    'val_accuracy/post_adapt_support',\n",
    "                    accuracy_post_adapt_support,\n",
    "                    i_step\n",
    "                )\n",
    "                writer.add_scalar(\n",
    "                    'val_accuracy/post_adapt_query',\n",
    "                    accuracy_post_adapt_query,\n",
    "                    i_step\n",
    "                )\n",
    "\n",
    "            if i_step % SAVE_INTERVAL == 0:\n",
    "                self._save(i_step)\n",
    "\n",
    "    def test(self, dataloader_test):\n",
    "        \"\"\"Evaluate the MAML on test tasks.\n",
    "\n",
    "        Args:\n",
    "            dataloader_test (DataLoader): loader for test tasks\n",
    "        \"\"\"\n",
    "        accuracies = []\n",
    "        for task_batch in dataloader_test:\n",
    "            _, _, accuracy_query = self._outer_step(task_batch, train=False)\n",
    "            if (math.isnan(accuracy_query.item())): break\n",
    "            accuracies.append(accuracy_query)\n",
    "        mean = np.mean(accuracies)\n",
    "        std = np.std(accuracies)\n",
    "        mean_95_confidence_interval = 1.96 * std / np.sqrt(NUM_TEST_TASKS)\n",
    "        print(\n",
    "            f'Accuracy over {NUM_TEST_TASKS} test tasks: '\n",
    "            f'mean {mean:.3f}, '\n",
    "            f'95% confidence interval {mean_95_confidence_interval:.3f}'\n",
    "        )\n",
    "\n",
    "    def load(self, checkpoint_step):\n",
    "        \"\"\"Loads a checkpoint.\n",
    "\n",
    "        Args:\n",
    "            checkpoint_step (int): iteration of checkpoint to load\n",
    "\n",
    "        Raises:\n",
    "            ValueError: if checkpoint for checkpoint_step is not found\n",
    "        \"\"\"\n",
    "        target_path = (\n",
    "            f'{os.path.join(self._log_dir, \"state\")}'\n",
    "            f'{checkpoint_step}.pt'\n",
    "        )\n",
    "        if os.path.isfile(target_path):\n",
    "            state = torch.load(target_path)\n",
    "            self._meta_parameters = state['meta_parameters']\n",
    "            self._inner_lrs = state['inner_lrs']\n",
    "            self._optimizer.load_state_dict(state['optimizer_state_dict'])\n",
    "            self._start_train_step = checkpoint_step + 1\n",
    "            print(f'Loaded checkpoint iteration {checkpoint_step}.')\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f'No checkpoint for iteration {checkpoint_step} found.'\n",
    "            )\n",
    "\n",
    "    def _save(self, checkpoint_step):\n",
    "        \"\"\"Saves parameters and optimizer state_dict as a checkpoint.\n",
    "\n",
    "        Args:\n",
    "            checkpoint_step (int): iteration to label checkpoint with\n",
    "        \"\"\"\n",
    "        optimizer_state_dict = self._optimizer.state_dict()\n",
    "        torch.save(\n",
    "            dict(meta_parameters=self._meta_parameters,\n",
    "                 inner_lrs=self._inner_lrs,\n",
    "                 optimizer_state_dict=optimizer_state_dict),\n",
    "            f'{os.path.join(self._log_dir, \"state\")}{checkpoint_step}.pt'\n",
    "        )\n",
    "        print('Saved checkpoint.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cpu\"\n",
    "# DEVICE = \"mps\"\n",
    "num_workers = 0\n",
    "if platform == \"linux\":\n",
    "    DEVICE = \"cuda\"\n",
    "    num_workers = 10\n",
    "\n",
    "log_dir = None\n",
    "writer = None\n",
    "\n",
    "log_dir = f'./logs/maml/'  # pylint: disable=line-too-long\n",
    "writer = tensorboard.SummaryWriter(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_way = 7\n",
    "num_inner_steps = 1\n",
    "inner_lr = 15.0\n",
    "learn_inner_lrs = True\n",
    "learning_rate = 0.01\n",
    "num_workers = 10\n",
    "\n",
    "maml = MAML(\n",
    "    num_way,\n",
    "    num_inner_steps,\n",
    "    inner_lr,\n",
    "    learn_inner_lrs,\n",
    "    learning_rate,\n",
    "    log_dir,\n",
    "    DEVICE\n",
    ")\n",
    "\n",
    "batch_size = 8\n",
    "num_way = 7\n",
    "num_support = 5\n",
    "num_query = 15\n",
    "num_training_tasks = 8000\n",
    "\n",
    "dataloader_meta_train = get_medmnist_dataloader(\n",
    "        medmnistdataset='dermamnist',\n",
    "        split='train',\n",
    "        batch_size=batch_size,\n",
    "        num_way=num_way,\n",
    "        num_support=num_support,\n",
    "        num_query=num_query,\n",
    "        num_tasks_per_epoch=num_training_tasks,\n",
    "        num_workers=num_workers,\n",
    "    )\n",
    "\n",
    "dataloader_meta_val = get_medmnist_dataloader(\n",
    "        medmnistdataset='dermamnist',\n",
    "        split='val',\n",
    "        batch_size=batch_size, #2\n",
    "        num_way=num_way,\n",
    "        num_support=num_support,\n",
    "        num_query=num_query, \n",
    "        num_tasks_per_epoch=num_training_tasks, # 2\n",
    "        num_workers=num_workers,\n",
    "    )\n",
    "\n",
    "maml.train(\n",
    "    dataloader_meta_train,\n",
    "    dataloader_meta_val,\n",
    "    writer\n",
    ")\n",
    "\n",
    "dataloader_meta_test = get_medmnist_dataloader(\n",
    "        medmnistdataset='dermamnist',\n",
    "        split='test',\n",
    "        batch_size=1,\n",
    "        num_way=num_way,\n",
    "        num_support=num_support,\n",
    "        num_query=num_query,\n",
    "        num_tasks_per_epoch=NUM_TEST_TASKS,\n",
    "        num_workers=num_workers,\n",
    "    )\n",
    "\n",
    "maml.test(dataloader_meta_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_INPUT_CHANNELS = 3\n",
    "NUM_HIDDEN_CHANNELS = 64\n",
    "KERNEL_SIZE = 3\n",
    "NUM_CONV_LAYERS = 4\n",
    "SUMMARY_INTERVAL = 10\n",
    "SAVE_INTERVAL = 100\n",
    "PRINT_INTERVAL = 10\n",
    "VAL_INTERVAL = PRINT_INTERVAL * 5\n",
    "NUM_TEST_TASKS = 100\n",
    "\n",
    "class ProtoNetNetwork(nn.Module):\n",
    "    \"\"\"Container for ProtoNet weights and image-to-latent computation.\"\"\"\n",
    "\n",
    "    def __init__(self, device):\n",
    "        \"\"\"Inits ProtoNetNetwork.\n",
    "\n",
    "        The network consists of four convolutional blocks, each comprising a\n",
    "        convolution layer, a batch normalization layer, ReLU activation, and 2x2\n",
    "        max pooling for downsampling. There is an additional flattening\n",
    "        operation at the end.\n",
    "\n",
    "        Note that unlike conventional use, batch normalization is always done\n",
    "        with batch statistics, regardless of whether we are training or\n",
    "        evaluating. This technically makes meta-learning transductive, as\n",
    "        opposed to inductive.\n",
    "\n",
    "        Args:\n",
    "            device (str): device to be used\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        in_channels = NUM_INPUT_CHANNELS\n",
    "        for _ in range(NUM_CONV_LAYERS):\n",
    "            layers.append(\n",
    "                nn.Conv2d(\n",
    "                    in_channels,\n",
    "                    NUM_HIDDEN_CHANNELS,\n",
    "                    (KERNEL_SIZE, KERNEL_SIZE),\n",
    "                    padding='same'\n",
    "                )\n",
    "            )\n",
    "            layers.append(nn.BatchNorm2d(NUM_HIDDEN_CHANNELS))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.MaxPool2d(2))\n",
    "            in_channels = NUM_HIDDEN_CHANNELS\n",
    "        layers.append(nn.Flatten())\n",
    "        self._layers = nn.Sequential(*layers)\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, images):\n",
    "        \"\"\"Computes the latent representation of a batch of images.\n",
    "\n",
    "        Args:\n",
    "            images (Tensor): batch of Omniglot images\n",
    "                shape (num_images, channels, height, width)\n",
    "\n",
    "        Returns:\n",
    "            a Tensor containing a batch of latent representations\n",
    "                shape (num_images, latents)\n",
    "        \"\"\"\n",
    "        return self._layers(images)\n",
    "\n",
    "\n",
    "class ProtoNet:\n",
    "    \"\"\"Trains and assesses a prototypical network.\"\"\"\n",
    "\n",
    "    def __init__(self, learning_rate, log_dir, device, compile=False, backend=None, learner=None, val_interval=None, save_interval=None, bio=False):\n",
    "        \"\"\"Inits ProtoNet.\n",
    "\n",
    "        Args:\n",
    "            learning_rate (float): learning rate for the Adam optimizer\n",
    "            log_dir (str): path to logging directory\n",
    "            device (str): device to be used\n",
    "        \"\"\"\n",
    "        self.device = device\n",
    "        if learner is None:\n",
    "            self._network = ProtoNetNetwork(device)\n",
    "        else: \n",
    "            self._network = learner.to(device)\n",
    "\n",
    "        self.val_interval = VAL_INTERVAL if val_interval is None else val_interval\n",
    "        self.save_interval = SAVE_INTERVAL if save_interval is None else save_interval\n",
    "        self.bio = bio\n",
    "\n",
    "        if(compile == True):\n",
    "            try:\n",
    "                self._network = torch.compile(self._network, backend=backend)\n",
    "                print(f\"ProtoNetNetwork model compiled\")\n",
    "            except Exception as err:\n",
    "                print(f\"Model compile not supported: {err}\")\n",
    "\n",
    "        self._optimizer = torch.optim.Adam(\n",
    "            self._network.parameters(),\n",
    "            lr=learning_rate\n",
    "        )\n",
    "        self._log_dir = log_dir\n",
    "        os.makedirs(self._log_dir, exist_ok=True)\n",
    "\n",
    "        self._start_train_step = 0\n",
    "\n",
    "    def _step(self, task_batch):\n",
    "        \"\"\"Computes ProtoNet mean loss (and accuracy) on a batch of tasks.\n",
    "\n",
    "        Args:\n",
    "            task_batch (tuple[Tensor, Tensor, Tensor, Tensor]):\n",
    "                batch of tasks from an Omniglot DataLoader\n",
    "\n",
    "        Returns:\n",
    "            a Tensor containing mean ProtoNet loss over the batch\n",
    "                shape ()\n",
    "            mean support set accuracy over the batch as a float\n",
    "            mean query set accuracy over the batch as a float\n",
    "        \"\"\"\n",
    "        loss_batch = []\n",
    "        accuracy_support_batch = []\n",
    "        accuracy_query_batch = []\n",
    "        for i, task in enumerate(task_batch):\n",
    "            # print(i)\n",
    "            images_support, labels_support, images_query, labels_query = task\n",
    "            images_support = images_support.to(self.device)\n",
    "            labels_support = labels_support.to(self.device)\n",
    "            images_query = images_query.to(self.device)\n",
    "            labels_query = labels_query.to(self.device)\n",
    "\n",
    "            ### START CODE HERE ###\n",
    "            # TODO: finish implementing this method.\n",
    "            # For a given task, compute the prototypes and the protonet loss.\n",
    "            # Use F.cross_entropy to compute classification losses.\n",
    "            # Use util.score to compute accuracies.\n",
    "            # Make sure to populate loss_batch, accuracy_support_batch, and\n",
    "            # accuracy_query_batch.\n",
    "            loss_batch, accuracy_support_batch, accuracy_query_batch\n",
    "            # compute prototypes without tracking gradients\n",
    "                # Generate support features\n",
    "            support_features = self._network.forward(images_support)\n",
    "            # Calculate prototypes from features\n",
    "            prototypes = []\n",
    "            n  = torch.unique(labels_support).shape[-1]\n",
    "            for i in range(n):\n",
    "                indices = (labels_support == i).nonzero()\n",
    "                class_features = support_features[indices]\n",
    "                with torch.no_grad():\n",
    "                    prototypes.append(torch.mean(class_features, dim=0))\n",
    "                # Calculate features for support\n",
    "            prototypes = torch.cat(prototypes)\n",
    "            support_features = torch.stack([support_features] * prototypes.size(0), dim=1)\n",
    "            supp_diffs = torch.sub(support_features, prototypes)\n",
    "            supp_sq_norms = torch.linalg.norm(supp_diffs,ord=2,dim=2).square()\n",
    "            accuracy_support_batch.append(score(-supp_sq_norms, labels_support))\n",
    "\n",
    "            # Generate query features\n",
    "            query_features = self._network.forward(images_query)\n",
    "            query_features_batch = torch.stack([query_features] * prototypes.size(0), dim=1)\n",
    "            query_diffs = torch.sub(query_features_batch, prototypes)\n",
    "            query_sq_norms = torch.linalg.norm(query_diffs,ord=2,dim=2).square()\n",
    "            accuracy_query_batch.append(score(-query_sq_norms, labels_query))\n",
    "            # Compute loss\n",
    "            loss_batch.append(F.cross_entropy(-query_sq_norms, labels_query))\n",
    "            ### END CODE HERE ###\n",
    "\n",
    "            # ********************************************************\n",
    "            # ******************* YOUR CODE HERE *********************\n",
    "            # ********************************************************\n",
    "        return (\n",
    "            torch.mean(torch.stack(loss_batch)),\n",
    "            np.mean(accuracy_support_batch),\n",
    "            np.mean(accuracy_query_batch)\n",
    "        )\n",
    "\n",
    "    def train(self, dataloader_meta_train, dataloader_meta_val, writer):\n",
    "        \"\"\"Train the ProtoNet.\n",
    "\n",
    "        Consumes dataloader_meta_train to optimize weights of ProtoNetNetwork\n",
    "        while periodically validating on dataloader_meta_val, logging metrics, and\n",
    "        saving checkpoints.\n",
    "\n",
    "        Args:\n",
    "            dataloader_meta_train (DataLoader): loader for train tasks\n",
    "            dataloader_meta_val (DataLoader): loader for validation tasks\n",
    "            writer (SummaryWriter): TensorBoard logger\n",
    "        \"\"\"\n",
    "        print(f'Starting training at iteration {self._start_train_step}.')\n",
    "        MAX_TRAIN = len(dataloader_meta_train)\n",
    "        # exit()\n",
    "        for i_step, task_batch in enumerate(\n",
    "                dataloader_meta_train,\n",
    "                start=self._start_train_step\n",
    "        ):\n",
    "            if i_step > MAX_TRAIN:\n",
    "                break\n",
    "            self._optimizer.zero_grad()\n",
    "            loss, accuracy_support, accuracy_query = self._step(task_batch)\n",
    "            loss.backward()\n",
    "            self._optimizer.step()\n",
    "\n",
    "            if i_step % PRINT_INTERVAL == 0:\n",
    "                print(\n",
    "                    f'Iteration {i_step}: '\n",
    "                    f'loss: {loss.item():.3f}, '\n",
    "                    f'support accuracy: {accuracy_support.item():.3f}, '\n",
    "                    f'query accuracy: {accuracy_query.item():.3f}'\n",
    "                )\n",
    "                writer.add_scalar('loss/train', loss.item(), i_step)\n",
    "                writer.add_scalar(\n",
    "                    'train_accuracy/support',\n",
    "                    accuracy_support.item(),\n",
    "                    i_step\n",
    "                )\n",
    "                writer.add_scalar(\n",
    "                    'train_accuracy/query',\n",
    "                    accuracy_query.item(),\n",
    "                    i_step\n",
    "                )\n",
    "\n",
    "            if i_step % self.val_interval == 0:\n",
    "                print(\"Start Validation...\")\n",
    "                with torch.no_grad():\n",
    "                    losses, accuracies_support, accuracies_query = [], [], []\n",
    "                    for i, val_task_batch in enumerate(dataloader_meta_val):\n",
    "                        if self.bio and i > 600:\n",
    "                            break\n",
    "                        loss, accuracy_support, accuracy_query = (\n",
    "                            self._step(val_task_batch)\n",
    "                        )\n",
    "                        losses.append(loss.item())\n",
    "                        accuracies_support.append(accuracy_support)\n",
    "                        accuracies_query.append(accuracy_query)\n",
    "                    loss = np.mean(losses)\n",
    "                    accuracy_support = np.mean(accuracies_support)\n",
    "                    accuracy_query = np.mean(accuracies_query)\n",
    "                    ci95 = 1.96 * np.std(accuracies_query) / np.sqrt(600 * 4)\n",
    "                if self.bio:\n",
    "                    print(\n",
    "                        f'Validation: '\n",
    "                        f'loss: {loss:.3f}, '\n",
    "                        f'support accuracy: {accuracy_support:.3f}, '\n",
    "                        f'query accuracy: {accuracy_query:.3f}',\n",
    "                        f'Ci95: {ci95:.3f}'\n",
    "                    )\n",
    "                else: \n",
    "                    print(\n",
    "                        f'Validation: '\n",
    "                        f'loss: {loss:.3f}, '\n",
    "                        f'support accuracy: {accuracy_support:.3f}, '\n",
    "                        f'query accuracy: {accuracy_query:.3f}'\n",
    "                    )\n",
    "                writer.add_scalar('loss/val', loss, i_step)\n",
    "                writer.add_scalar(\n",
    "                    'val_accuracy/support',\n",
    "                    accuracy_support,\n",
    "                    i_step\n",
    "                )\n",
    "                writer.add_scalar(\n",
    "                    'val_accuracy/query',\n",
    "                    accuracy_query,\n",
    "                    i_step\n",
    "                )\n",
    "                if self.bio:\n",
    "                    writer.add_scalar(\n",
    "                        'val_accuracy/ci95',\n",
    "                        ci95,\n",
    "                        i_step\n",
    "                    )\n",
    "            if i_step % self.save_interval == 0:\n",
    "                self._save(i_step)\n",
    "\n",
    "    def test(self, dataloader_test):\n",
    "        \"\"\"Evaluate the ProtoNet on test tasks.\n",
    "\n",
    "        Args:\n",
    "            dataloader_test (DataLoader): loader for test tasks\n",
    "        \"\"\"\n",
    "        accuracies = []\n",
    "        for i, task_batch in enumerate(dataloader_test):\n",
    "            accuracies.append(self._step(task_batch)[2])\n",
    "        mean = np.mean(accuracies)\n",
    "        std = np.std(accuracies)\n",
    "        mean_95_confidence_interval = 1.96 * std / np.sqrt(NUM_TEST_TASKS)\n",
    "        print(\n",
    "            f'Accuracy over {NUM_TEST_TASKS} test tasks: '\n",
    "            f'mean {mean:.3f}, '\n",
    "            f'95% confidence interval {mean_95_confidence_interval:.3f}'\n",
    "        )\n",
    "\n",
    "    def load(self, checkpoint_step, filename=\"\"):\n",
    "        \"\"\"Loads a checkpoint.\n",
    "\n",
    "        Args:\n",
    "            checkpoint_step (int): iteration of checkpoint to load\n",
    "            filename (str): directly setting name of checkpoint file, default =\"\", when argument is passed, then checkpoint will be ignored\n",
    "\n",
    "        Raises:\n",
    "            ValueError: if checkpoint for checkpoint_step is not found\n",
    "        \"\"\"\n",
    "        target_path = (\n",
    "            f'{os.path.join(self._log_dir, \"state\")}'\n",
    "            f'{checkpoint_step}.pt'\n",
    "        ) if filename == \"\" else filename\n",
    "        if os.path.isfile(target_path):\n",
    "            state = torch.load(target_path)\n",
    "            self._network.load_state_dict(state['network_state_dict'])\n",
    "            self._optimizer.load_state_dict(state['optimizer_state_dict'])\n",
    "            self._start_train_step = checkpoint_step + 1\n",
    "            print(f'Loaded checkpoint iteration {checkpoint_step}.')\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f'No checkpoint for iteration {checkpoint_step} found.'\n",
    "            )\n",
    "\n",
    "    def _save(self, checkpoint_step):\n",
    "        \"\"\"Saves network and optimizer state_dicts as a checkpoint.\n",
    "\n",
    "        Args:\n",
    "            checkpoint_step (int): iteration to label checkpoint with\n",
    "        \"\"\"\n",
    "        torch.save(\n",
    "            dict(network_state_dict=self._network.state_dict(),\n",
    "                 optimizer_state_dict=self._optimizer.state_dict()),\n",
    "            f'{os.path.join(self._log_dir, \"state\")}{checkpoint_step}.pt'\n",
    "        )\n",
    "        print('Saved checkpoint.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "backend = 'inductor'\n",
    "\n",
    "batch_size = 16\n",
    "num_way = 7\n",
    "num_support = 10\n",
    "num_query = 15\n",
    "num_training_tasks = 8000\n",
    "\n",
    "log_dir = f'./logs/protonet/'  # pylint: disable=line-too-long\n",
    "writer = tensorboard.SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "dataloader_meta_train = get_medmnist_dataloader(\n",
    "        medmnistdataset='dermamnist',\n",
    "        split='train',\n",
    "        batch_size=batch_size,\n",
    "        num_way=num_way,\n",
    "        num_support=num_support,\n",
    "        num_query=num_query,\n",
    "        num_tasks_per_epoch=num_training_tasks,\n",
    "        num_workers=num_workers,\n",
    "    )\n",
    "\n",
    "dataloader_meta_val = get_medmnist_dataloader(\n",
    "        medmnistdataset='dermamnist',\n",
    "        split='val',\n",
    "        batch_size=batch_size, #2\n",
    "        num_way=num_way,\n",
    "        num_support=num_support,\n",
    "        num_query=num_query, \n",
    "        num_tasks_per_epoch=num_training_tasks, # 2\n",
    "        num_workers=num_workers,\n",
    "    )\n",
    "\n",
    "protonet = ProtoNet(learning_rate, log_dir, DEVICE, backend)\n",
    "\n",
    "protonet.train(\n",
    "        dataloader_meta_train,\n",
    "        dataloader_meta_val,\n",
    "        writer\n",
    "    )\n",
    "\n",
    "dataloader_meta_test = get_medmnist_dataloader(\n",
    "        medmnistdataset='dermamnist',\n",
    "        split='test',\n",
    "        batch_size=1,\n",
    "        num_way=num_way,\n",
    "        num_support=num_support,\n",
    "        num_query=num_query,\n",
    "        num_tasks_per_epoch=NUM_TEST_TASKS,\n",
    "        num_workers=num_workers,\n",
    "    )\n",
    "\n",
    "protonet.test(dataloader_meta_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs330_project_hw2",
   "language": "python",
   "name": "cs330_project_hw2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
